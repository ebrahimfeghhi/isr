In run 0, forgot to ignore end of list cue when computing 
accuracy. Updated this on run 1.

In run 2, model operates on float64. 

In run 3, removed negative -1 bias init. for output units. 

In run 4, number of letters is reduced to 12 (from 26) to be more in line with Henson.

In run 5, sigmoid is only applied to hidden activations from previous timestep, and 
not input and output from previous timestep. 

In run 6, inputs are 1 item shorter and model no longer needs to output end of list cue. 
Model is trained with 12 letters. Run 7 is identical but model is trained with 26 letters. 





